---
title: An Entropy-Efficient Virtual Dice Rolling Algorithm
layout: post
tags: [math, lisp, compsci]
uuid: 6557ed4d-1d59-3f17-19ec-9174393a9360
---

<!-- 28 August 2009 -->
<p class="abstract">
<img src="/img/dice/roll.png" alt="" title="5d6" class="right" />

This is related to a project I am working on and will post here
soon. I imagine that, with a little more effort, this algorithm could
turn into a short amateur <a
href="http://en.wikipedia.org/wiki/Academic_publishing"> paper</a>.
</p>
<p>
Suppose you want to use a computer to simulate the roll of two
six-sided dice (notated <code>2d6</code>). The simplest approach would
be to replicate the results the same way you would roll dice:
independently and randomly generate two numbers between 1 and 6
inclusively. We easily can do this for any number of dice, we just
iterate and roll each die. Like this recursive function,
</p>
{% highlight cl %}
(defun roll (n sides)
  "Roll n dice with given number of sides."
  (if (zerop n) ()
    (cons (1+ (random sides))
          (roll (1- n) sides))))
{% endhighlight %}
<p>
However, generating a number between 1 and 6 wastes small amounts of
entropy. A six-sided die only takes about 2.58 bits of entropy to
generate. Since we can only use bits discretely we have to spend 3
bits, throwing out 0.42 bits. On top of that, when we pull out 3 bits
and they are out of range (0 or 7) we have to throw them out and try
again.
</p>
<p>
Let's say we wanted to roll 10 dice, or 100 dice, or 1000 dice? Do we
really need to generate that many numbers individually? That's a lot
of wasted entropy adding up, entropy which can be expensive to
gather. Well, we could instead <b>use the probability distribution of
the roll so that only a single number needs to be generated</b>.
</p>
<p>
For a <code>2d6</code> roll, there are 36 unique possible outcomes
(6^2). We could select a number between 0 and 35, then choose that
specific roll. This roll can be calculated with a series of division
and modulus operations (<code>u</code> for a number from a <a
href="http://en.wikipedia.org/wiki/Uniform_distribution_(discrete)">
uniform distribution</a>) (also, note that the division is <a
href="http://en.wikipedia.org/wiki/Integer_division#Division_of_integers">
integer division</a>),
</p>
{% highlight cl %}
(defun roll-perm (n s u)
  "Get uth permutation of n s-sided dice."
  (if (zerop n) ()
    (let ((perms (expt s (1- n))))
      (cons (1+ (/ u perms))
            (roll-perm (1- n) s (mod u perms))))))
{% endhighlight %}
<p>
If we're only interested in the sum, we could save memory by making
this tail recursive — or iterative — and summing the dice as we
calculate them. Ignoring the exponent, this is <code>O(n)</code>, not
better than the simple algorithm in terms of growth rate. This
algorithm is more efficient when it comes to entropy, though.
</p>
<p>
Consider <code>3d6</code>, with 216 possible outcomes, ideally with
the simple algorithm takes 3 3-bit rolls, consuming 9 bits. About 1.25
bits was not actually used (0.42 * 3). In the entropy-efficient
algorithm we need about 7.75 bits, so it only consumes 8 bits of
entropy. We saved a bit. That gap only gets larger with more dice. For
<code>100d6</code> the simple algorithm uses 41 more bits than
necessary.
</p>
<p class="center">
  <img src="/img/diagram/dice-bits.png" alt="">
</p>
<p>
The efficient roll is basically defragmenting the individual rolls on
the entropy stream.
</p>
<p>
In non-ideal world, though, some cases don't work out well. In
<code>12d6</code>, almost half the numbers (compared to 25% in the
case of 1d6) from the uniform distribution will be out of range and a
lot more bits would be needed. On average, rolling dice individually
(or only <i>some</i> of them individually) for <code>12d6</code> will
be more efficient.
</p>
<p>
The efficient algorithm is only more efficient above a point near
where <code>mod(log2(s), 1) &lt; mod(log2(n^s), 1)</code>.
</p>
<p>
And, all of this doesn't come without a cost. You must pay the piper,
and this algorithm is paid with CPU and memory. Notice that exponent
there? That has to be done to exact precision (no floating point), and
it grows very quickly. If you want to roll more than a handful of
dice, you will be crunching some large numbers. Rolling just
<code>100d6</code> means you have to work with a 78 digit
integer. <code>10000d6</code> is a 7782 digit integer. These can't be
done in floating point because the resolution of floating point is too
low: some rolls would not be possible.
</p>
<p>
The exponent could be <a href="/blog/2008/03/25/">memoized</a> to
trade some of that CPU time for more memory usage. Still, pretty
costly. If you don't value your entropy, the tradeoff might not be
worth it.
</p>
<p>
I can't see a way around performing that calculation. We need to know
that big number exactly. Perhaps a mathematician might be able to
manipulate the formulas such that it's not so expensive.
</p>
<p>
If you're rolling lots of dice and you want to preserve binary
entropy, try it out. If you want to be really efficient queue up rolls
— or generate them ahead of time — so that the number of outcomes is
just below a power of two. In the case of <code>d6</code>, some good
number of dice to roll are 17 (~43.94 bits), 29 (~74.96), 41
(~105.983), 94 (~242.986 bits), 200 (~516.993), 253 (~653.995 bits),
306 (~791.99853 bits), and 971 (~2509.99859 bits). (Notice these get
closer and closer to an integer number of bits.)
</p>
